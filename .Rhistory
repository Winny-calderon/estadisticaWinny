library(haven)
data <- read_sav("C:/Users/WINNY CALDERON/Downloads/LAPOP20172016.sav")
View(data)
x <- 8
z <- 10
x+z
name(data)
library(haven)
dato <- read_sav("C:/Users/WINNY CALDERON/Downloads/LAPOP20172016.sav")
View(dato)
name(dato)
ame(dato)
name(dato)
View(data)
name(data)
name (data)
names(data)
str(data)
data$q1=as.factor(data$q1)
install.packages("rio")
library(rio)
library(rio)
link_del_github="https://github.com/DataPolitica/salidas/raw/master/Data/trabajadores.sav"
trabajadores=import(link_del_github)
names(trabajadores)
setwd("~/PUCP/6to CICLO/ANAL POL COMPARADO (POL231)/Estadística/estadisticaWinny")
library(stringr)
library(magrittr)
library(htmltab)
library(factoextra)
library(cluster)
library(ggrepel)
library(foreign)
```
0.- BAJAMOS LA DATA ORIGINAL, OMITIMOS PERDIDOS, COLOCAMOS NOMBRE A LAS FILAS Y CREAMOS UNA SUBDATA CON LAS VARIABLES NUMÉRICAS A UTILIZAR EN NUESTRO CÁLCULOS DE CONGLOMERADOS (OJO CON ESTO)
```{r}
library(rio)
regiones<-import("regiones.xlsx")
str(regiones)
regiones <- regiones[,c(1, 4:6)]
row.names(regiones)=regiones$region
regiones$region= NULL
subdata<-regiones
subdata<-na.omit(subdata)
```
########################################################################################
Creamos una base llamada "subdata" que tenga exclusivamente las columnas que utilizaremos para el cálculo de los cluster
########################################################################################
IDENTIFICAR EL NÚMERO DE CLUSTER ADECUADO (EN PARTICIÓN Y JERÁRQUICO)
Realizamos los cálculos con la subdata creada.
```{r}
#CALCULAMOS LAS DISTANCIAS CON DAYSY
g.dist = daisy(subdata, metric="gower")
#NÚMERO DE CLUSTER PARA PARTICIÓN (colocamos pam)
fviz_nbclust(subdata, pam,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F)
#Número de clusters para jerarquización (colocamos hcut)
fviz_nbclust(subdata, hcut,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F)
particion = pam(g.dist,3,cluster.only = F) #Indicamos 3 por el resultado anterior
aglomerativo = hcut(g.dist, k = 3,hc_func='agnes',hc_method = "ward.D") #Indicamos 3 por el resultado anterior
divisivo = hcut(g.dist, k = 3,hc_func='diana') #Indicamos 3 por el resultado anterior
fviz_silhouette(particion)
fviz_silhouette(aglomerativo)
fviz_silhouette(divisivo)
head(particion$silinfo$widths)
widths.particion=data.frame(particion$silinfo$widths)
View(widths.particion)
widths.particion$Id=row.names(widths.particion)
malos.widths.particion=widths.particion[widths.particion$sil_width<0,'Id']
malos.widths.particion
length(malos.widths.particion)
head(aglomerativo$silinfo$widths)
widths.aglomerativo=data.frame(aglomerativo$silinfo$widths)
widths.aglomerativo$Id=row.names(widths.aglomerativo)
malos.widths.aglomerativo=widths.aglomerativo[widths.aglomerativo$sil_width<0,'Id']
malos.widths.aglomerativo
length(malos.widths.aglomerativo)
View(aglomerativo)
View(widths.aglomerativo)
# Revisamos cómo se ve ese elemento widths
head(divisivo$silinfo$widths)
# Creamos un data.frame que sea equivalente a ese elemento
widths.divisivo=data.frame(divisivo$silinfo$widths)
# Creamos un vector que sea el nombre de la región. Lo jalamos del nombre de la fila.
widths.divisivo$Id=row.names(widths.divisivo)
# Creamos un objeto que sea los nombres de aquellos casos cuyos widths sean menor a 0.
malos.widths.divisivo=widths.divisivo[widths.divisivo$sil_width<0,'Id']
malos.widths.divisivo
#cantidad de casos
length(malos.widths.divisivo)
proyeccion = cmdscale(g.dist, k=2,add = T)
View(proyeccion)
subdata$dim1 <- proyeccion$points[,1]
subdata$dim2 <- proyeccion$points[,2]
base= ggplot(subdata,aes(x=dim1, y=dim2,label=row.names(subdata)))
base + geom_text(size=2)
subdata$c.particion=as.factor(particion$clustering)
subdata$c.aglomerativo=as.factor(aglomerativo$cluster)
subdata$c.divisivo=as.factor(divisivo$cluster)
min(subdata[,c('dim1','dim2')]); max(subdata[,c('dim1','dim2')])
limites=c(-0.49,0.52)
base= ggplot(subdata,aes(x=dim1, y=dim2)) + ylim(limites) + xlim(limites) + coord_fixed()
base + geom_point(size=2, aes(color=c.particion))  + labs(title = "PARTICIONANTE")
base + geom_point(size=2, aes(color=c.aglomerativo)) + labs(title = "AGLOMERATIVO")
base + geom_point(size=2, aes(color=c.divisivo)) + labs(title = "DIVISIVO")
g.dist.cmd = daisy(subdata[,c('dim1','dim2')], metric = 'euclidean')
library(dbscan)
kNNdistplot(g.dist.cmd, k=5)
abline(h=0.12, lty=2)
kNNdistplot(g.dist.cmd, k=5)
library(dbscan)
kNNdistplot(g.dist.cmd, k=5)
abline(h=0.12, lty=2)
install.packages("fpc")
library(fpc)
db.cmd = dbscan(g.dist.cmd, eps=0.12, MinPts=5, method = 'dist')
db.cmd
db.cmd
library(fpc)
subdata$c.densidad=as.factor(db.cmd$cluster)
install.packages("ggrepel")
install.packages("ggrepel")
library(ggplot2)
library(ggrepel)
base= ggplot(subdata,aes(x=dim1, y=dim2)) + ylim(limites) + xlim(limites) + coord_fixed()
dbplot= base + geom_point(aes(color=c.densidad))
dbplot
dbplot + geom_text_repel(size=5,aes(label=row.names(subdata)))
LABEL=ifelse(subdata$c.densidad==0,row.names(subdata),"")
dbplot + geom_text_repel(aes(label=LABEL),
size=5,
direction = "x", ylim = 0.45,
angle=45,
segment.colour = "grey")
link="https://en.wikipedia.org/wiki/World_Happiness_Report"
linkPath='//*[@id="mw-content-text"]/div[1]/table'
library(htmltab)
data= htmltab(doc =link,
which =linkPath)
str(data)
class(data)
View(data)
data$`Overall rank`=NULL
data$Score=NULL
names(data)=c("Country","GDP","Support","Healthy","Freedom", "Generosity", "Perceptions")
#Espacios en blanco:
names(data)
lapply(data, trimws,whitespace = "[\\h\\v]")
data$Country=gsub('Â',"",data$Country)
names(data$Country)
str(data$Country)
lapply(data$Country trimws,whitespace = "[\\h\\v]"
lapply(data$Country trimws,whitespace = "[\\h\\v]")
lapply(data$Country, trimws,whitespace = "[\\h\\v]")
data$Country=lapply(data$Country, trimws,whitespace = "[\\h\\v]")
str(data)
class(data)
str(data)
lapply(data[,-c(1)], as.numeric)
data[,-c(1)]=lapply(data[,-c(1)], as.numeric)
str(data$GDP)
str(data$Perceptions)
data=na.omit(data)
row.names(data)=data$Country
data$Country=NULL
subdata<-data
subdata<-na.omit(subdata)
View(subdata)
g.dist = daisy(subdata, metric="gower")
library(stringr)
library(magrittr)
library(htmltab)
library(factoextra)
library(cluster)
library(ggrepel)
library(foreign)
g.dist = daisy(subdata, metric="gower")
fviz_nbclust(subdata, pam,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F)
fviz_nbclust(subdata, hcut,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F)
particion = pam(g.dist,7,cluster.only = F)
aglomerativo = hcut(g.dist, k = 5,hc_func='agnes',hc_method = "ward.D")
fviz_silhouette(particion)
#AGLOMERATIVO:
fviz_silhouette(aglomerativo)
#DIVISIVO:
fviz_silhouette(divisivo)
divisivo = hcut(g.dist, k = 5,hc_func='diana')
fviz_silhouette(divisivo)
proyeccion = cmdscale(g.dist, k=2,add = T)
subdata$dim1 <- proyeccion$points[,1]
subdata$dim2 <- proyeccion$points[,2]
base= ggplot(subdata,aes(x=dim1, y=dim2,label=row.names(subdata)))
base + geom_text(size=2)
subdata$c.particion=as.factor(particion$clustering)
subdata$c.aglomerativo=as.factor(aglomerativo$cluster)
subdata$c.divisivo=as.factor(divisivo$cluster)
min(subdata[,c('dim1','dim2')]); max(subdata[,c('dim1','dim2')])
limites=c(-0.52,0.54)
base= ggplot(subdata,aes(x=dim1, y=dim2)) + ylim(limites) + xlim(limites) + coord_fixed()
base + geom_point(size=2, aes(color=c.particion))  + labs(title = "PARTICIONANTE")
base + geom_point(size=2, aes(color=c.aglomerativo)) + labs(title = "AGLOMERATIVO")
base + geom_point(size=2, aes(color=c.divisivo)) + labs(title = "DIVISIVO")
library(dbscan)
g.dist.cmd = daisy(subdata[,c('dim1','dim2')], metric = 'euclidean')
kNNdistplot(g.dist.cmd, k=5)
install.packages("fpc")
library(fpc)
db.cmd = dbscan(g.dist.cmd, eps=0.15, MinPts=6, method = 'dist')
db.cmd
g.dist.cmd
db.cmd
